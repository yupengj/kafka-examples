version: '2'
services:
  zookeeper:
    image: zookeeper:3.5.5
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - /home/jyp/volume/zksingle/data:/data
      - /home/jyp/volume/zksingle/datalog:/datalog

  kafka:
    image: wurstmeister/kafka:2.12-2.3.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1 # 设置 broker 属性时 kafka 的 ip 换了也不会影响 topics 的读取。
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://192.168.1.6:9092 # 192.168.1.6 是虚拟机的iP , 如果是本地就可以写 localhost:9092
      KAFKA_CREATE_TOPICS: "test1:1:1" # 自动创建一个 名称为 test1 的 topic 分区是1 副本是1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_RETENTION_HOURS: 700800
      JMX_PORT: 9999
    volumes:
      - /home/jyp/volume/kfksingle/logs:/kafka # kafak 数据挂载到主机地址

  connect:
    image: my-kafka-connect:1.0.0
    container_name: kafka-connect
    ports:
      - "8083:8083"
    links:
      - zookeeper
      - kafka
      - postgresql
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083 # Kafka connect creates an endpoint in order to add connectors
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_ZOOKEEPER_CONNECT: zookeeper:2181
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-config
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1 # We have only 1 broker, so we can only have 1 replication factor.
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter" # We receive a string as key and a json as value
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/java,/etc/kafka-connect/jars
    volumes:
      - /home/jyp/volume/connect-plugins:/etc/kafka-connect/jars # 用于存放扩展连接器的jar

  kafka-manager:
    image: sheepkiller/kafka-manager
    container_name: kafka-manager
    hostname: kafka-manager
    ports:
      - "9000:9000"
    links:
      - kafka
      - zookeeper
    environment:
      KM_VERSION: 2.0.0.2
      ZK_HOSTS: "zookeeper"
      APPLICATION_SECRET: "letmein"

  postgresql:
    image: debezium/postgres:10-alpine
    container_name: postgresql
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: 123456
    volumes:
      - /home/jyp/volume/postgresql/data:/var/lib/postgresql/data
